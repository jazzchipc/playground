{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# my-notebook\n",
    "\n",
    "This notebook contains my initial approach and familiarization with Pommerman.\n",
    "\n",
    "I will be building my solution for the Team Radio competition ([competitions page](https://www.pommerman.com/competitions)).\n",
    "\n",
    "## TODOS\n",
    "\n",
    "- Check difference between `radio_v2` and `radio_competition` envs. --> No difference. Two IDs lead to the same environment.\n",
    "- Figure out how to get the information from the envs.\n",
    "- Figure out if there's any way a human could play.\n",
    "- Ask direction, position and flames values on Discord.\n",
    "- Check this: https://github.com/gorogm/pommerman_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "\n",
    "The most important is the `pommerman` package that is in the root directory, and from which we will be importing modules that are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just checking that we're running the Python version we want\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import pommerman\n",
    "from pommerman.agents import SimpleAgent, RandomAgent, PlayerAgent, BaseAgent\n",
    "from pommerman.envs.v0 import Pomme\n",
    "from pommerman.characters import Bomber\n",
    "from pommerman import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Radio environment\n",
    "\n",
    "I believe the available environments are based on OpenAI Gym environments.\n",
    "\n",
    "There is a `configs.py` file with the configurations of each environment. To create a `PommeRadioCompetition-v2` environment, we execute the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PommeFFACompetition-v0', 'PommeFFACompetitionFast-v0', 'PommeFFAFast-v0', 'PommeFFA-v1', 'OneVsOne-v0', 'PommeRadioCompetition-v2', 'PommeRadio-v2', 'PommeTeamCompetition-v0', 'PommeTeamCompetitionFast-v0', 'PommeTeamCompetition-v1', 'PommeTeam-v0', 'PommeTeamFast-v0']\n"
     ]
    }
   ],
   "source": [
    "# Print all possible environments in the Pommerman registry\n",
    "print(pommerman.REGISTRY)\n",
    "\n",
    "# Create a set of agents (exactly four)\n",
    "agent_list = [\n",
    "    SimpleAgent(),\n",
    "    RandomAgent(),\n",
    "    SimpleAgent(),\n",
    "    RandomAgent()\n",
    "    # agents.DockerAgent(\"pommerman/simple-agent\", port=12345),\n",
    "]\n",
    "\n",
    "# Make the \"TeamCompetition\" environment using the agent list\n",
    "env = pommerman.make('PommeRadioCompetition-v2', agent_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed and reset the environment\n",
    "env.seed(0)\n",
    "obs = env.reset()\n",
    "\n",
    "# Run the random agents until we're done with one episode (test)\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    actions = env.act(obs)\n",
    "    obs, reward, done, info = env.step(actions)\n",
    "env.render(close=True)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actions and Observations\n",
    "\n",
    "As described [here](https://www.pommerman.com/about), [here](https://docs.pommerman.com/environment/) and [here](https://github.com/MultiAgentLearning/playground/blob/master/docs/environment.md).\n",
    "\n",
    "When playing in the `PommeRadioCompetition-v2` an observation variable comes with two observations - one for each agent we control.\n",
    "\n",
    "### Alive \n",
    "\n",
    "A list containing the IDs of the agents that are still alive (10 is Agent0, 11 is Agent1, ...)\n",
    "\n",
    "### Board\n",
    "\n",
    "The board is a 11x11 numpy array, where each value corresponds to a representation:\n",
    "\n",
    "- 0 = Passage\n",
    "- 1 = Rigid Wall -- cannot be broken\n",
    "- 2 = Wooden Wall -- can be broken and half of them have power-ups\n",
    "- 3 = Bomb\n",
    "- 4 = Flames\n",
    "- 5 = Fog (only applicable in partially observed scenarios like 2v2 Team Radio)\n",
    "- 6 = Extra Bomb Power-Up -- adds ammo\n",
    "- 7 = Increase Range Power-Up -- increases the `blast_strength`\n",
    "- 8 = Can Kick Power-Up -- a player can kick bombs by touching them\n",
    "- 9 = Agent Dummy\n",
    "- 10 = Agent0\n",
    "- 11 = Agent1\n",
    "- 12 = Agent2\n",
    "- 13 = Agent3\n",
    "\n",
    "### Bomb_Blast_Strength\n",
    "\n",
    "\n",
    "A 11x11 numpy matrix that contains every position a bomb of the agent might be in. It's `0` if there's no bomb there. Any other number represents the blast strength of the current agent's bombs. \n",
    "\n",
    "A value different than `0` represents how many squares the flame of the bomb occupies. An agent starts with a bomb strength of `3`.\n",
    "\n",
    "### Bomb_Life\n",
    "\n",
    "A 11x11 numpy matrix that contains the life of all bombs in the agent's field of view. A bomb has a life time of **10 timesteps**. The number in the matrix indicates the number of timesteps left until it blows.\n",
    "\n",
    "### Bomb_Moving_Direction\n",
    "\n",
    "A 11x11 numpy array that contains the moving direction of all the bombs in the agent's field of view. A bomb travels at **1 unit per timestep** in the direction it was kicked.\n",
    "\n",
    "TODO: I am unsure about what values correspond to which direction.\n",
    "\n",
    "### Flame_Life\n",
    "\n",
    "A 11x11 numpy array that contains the life of the flame in a given position.\n",
    "\n",
    "TODO: I do not the value of the flame life when the bomb blows up.\n",
    "\n",
    "### Game_Type\n",
    "\n",
    "TODO: Dunno\n",
    "\n",
    "### Game_Env\n",
    "\n",
    "A string with the ID of the environment being used for the game.\n",
    "\n",
    "### Position\n",
    "\n",
    "A tuple with 2 ints. The position of the current agent in the board. Each integer is between **[0, 10]**.\n",
    "\n",
    "TODO: Where is (0,0)?\n",
    "\n",
    "### Blast_Strength\n",
    "\n",
    "An int with the agent's current blast strength.\n",
    "\n",
    "### Can_Kick\n",
    "\n",
    "A boolean which says if the agent can kick bombs or not.\n",
    "\n",
    "### Teammate\n",
    "\n",
    "TODO: Not sure about the type.\n",
    "\n",
    "### Ammo\n",
    "\n",
    "An int with the agent's current ammo (number of bombs it can drop right now).\n",
    "\n",
    "### Enemies\n",
    "\n",
    "TODO: Not sure about the type.\n",
    "\n",
    "### Step_Count\n",
    "\n",
    "Number of steps since beggining of the game.\n",
    "\n",
    "### Message\n",
    "\n",
    "A list of two Ints, each in [0, 8]. The message being relayed from the teammate. Both ints are zero when a teammate is dead or it's the first step. Otherwise they are in [1, 8].\n",
    "\n",
    "## Rewards\n",
    "\n",
    "Rewards listed have been deduced from [here](https://github.com/MultiAgentLearning/playground/blob/69da607015ef52b9f8e5b09f42a76e050cd22cff/pommerman/forward_model.py#L630).\n",
    "\n",
    "### Team Game\n",
    "\n",
    "- `-1` when the other team wins\n",
    "- `+1` when our team wins\n",
    "- `0` if no one has lost yet\n",
    "- `-1` for everyone if `max_steps` are surpassed\n",
    "- `-1` when everyone is dead (tie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example of an observation\n",
    "\n",
    "# Seed and reset the environment\n",
    "env.seed(0)\n",
    "obs = env.reset()\n",
    "\n",
    "print (env.action_space)\n",
    "\n",
    "# Run the random agents and print the 10th observation (for analysis)\n",
    "done = False\n",
    "it = 0\n",
    "while not done:\n",
    "    env.render()\n",
    "    actions = env.act(obs)\n",
    "    print(actions)\n",
    "    obs, reward, done, info = env.step(actions)\n",
    "    \n",
    "    it = it + 1\n",
    "    if it > 10:\n",
    "        print (obs)\n",
    "        break\n",
    "env.render(close=True)\n",
    "env.close()\n",
    "\n",
    "print(info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pommerman.env",
   "language": "python",
   "name": "pommerman.env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
